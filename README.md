<img width="1920" height="1200" alt="Screenshot 2025-07-13 174459" src="https://github.com/user-attachments/assets/5e7460d8-ac69-464e-bc2f-d0e96ad38c15" />
<img width="1920" height="1200" alt="Screenshot 2025-07-13 174444" src="https://github.com/user-attachments/assets/e67adfa9-4dfc-4fca-91a4-2780fdc5366a" />
# ğŸ§© Perplexity Clone â€” FastAPI Backend

This is the **FastAPI backend** for your Perplexity clone.
It does web search, sorts relevant sources, and generates answers using the Google Gemini LLM.

---

## ğŸš€ Features

* ğŸ” Search with Tavily API
* ğŸ—‚ï¸ Extract & clean webpage content using Trafilatura
* ğŸ§  Rank sources with sentence-transformers
* ğŸ¤– Generate final answers with Gemini
* ğŸ”— REST & WebSocket endpoints

---

## âš™ï¸ Tech Stack

* FastAPI
* Uvicorn
* Tavily API
* Trafilatura
* Sentence Transformers
* Google Generative AI (Gemini)
* Pydantic & dotenv for config

---

## ğŸ“ Project Structure

```
server/
 â”œâ”€â”€ main.py
 â”œâ”€â”€ config.py
 â”œâ”€â”€ services/
 â”‚   â”œâ”€â”€ llm_service.py
 â”‚   â”œâ”€â”€ search_service.py
 â”‚   â””â”€â”€ sort_source_service.py
 â”œâ”€â”€ pydantic_models/
 â”œâ”€â”€ requirements.txt
 â”œâ”€â”€ .env.example
render.yaml
Procfile (optional)
```

---

## ğŸ—ï¸ Environment Variables

Create a `.env` file:

```env
GEMINI_API_KEY=your-gemini-api-key
TAVILY_API_KEY=your-tavily-api-key
```

---

## ğŸ§© Local Development

```bash
# 1. Create a virtual env
python -m venv venv

# 2. Activate it
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run the server
uvicorn main:app --reload
```

Docs: [http://localhost:8000/docs](http://localhost:8000/docs)
WebSocket: ws\://localhost:8000/ws/chat

---

## ğŸŒ Deploy to Render

1ï¸âƒ£ Commit your code with `requirements.txt` and `render.yaml`.

Example `render.yaml`:

```yaml
services:
  - type: web
    name: perplexity-backend
    env: python
    plan: free
    buildCommand: ""
    startCommand: uvicorn main:app --host 0.0.0.0 --port $PORT
    envVars:
      - key: GEMINI_API_KEY
        sync: false
      - key: TAVILY_API_KEY
        sync: false
```

2ï¸âƒ£ Push to GitHub.

3ï¸âƒ£ Go to [https://dashboard.render.com/](https://dashboard.render.com/), click **New + â†’ Web Service**, connect your repo.

4ï¸âƒ£ Add your environment variables (`GEMINI_API_KEY` and `TAVILY_API_KEY`).

5ï¸âƒ£ Deploy! Your backend will be live at:

```
https://your-app-name.onrender.com
```

---

## âœ… Endpoints

### POST `/chat`

Input:

```json
{
  "query": "What is FastAPI?"
}
```

Response: full answer generated by the LLM.

---

### WebSocket `/ws/chat`

1. Connect to `wss://your-app-name.onrender.com/ws/chat`
2. Send `{ "query": "Your question" }`
3. Receive:

   * `search_result`
   * streamed `content` chunks

---

## ğŸ“œ License

MIT

---

**FastAPI. Gemini. Search. Sorted. ğŸš€**
