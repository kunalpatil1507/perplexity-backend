<img width="1920" height="1200" alt="Screenshot 2025-07-13 174459" src="https://github.com/user-attachments/assets/5e7460d8-ac69-464e-bc2f-d0e96ad38c15" />
<img width="1920" height="1200" alt="Screenshot 2025-07-13 174444" src="https://github.com/user-attachments/assets/e67adfa9-4dfc-4fca-91a4-2780fdc5366a" />
# 🧩 Perplexity Clone — FastAPI Backend

This is the **FastAPI backend** for your Perplexity clone.
It does web search, sorts relevant sources, and generates answers using the Google Gemini LLM.

---

## 🚀 Features

* 🔍 Search with Tavily API
* 🗂️ Extract & clean webpage content using Trafilatura
* 🧠 Rank sources with sentence-transformers
* 🤖 Generate final answers with Gemini
* 🔗 REST & WebSocket endpoints

---

## ⚙️ Tech Stack

* FastAPI
* Uvicorn
* Tavily API
* Trafilatura
* Sentence Transformers
* Google Generative AI (Gemini)
* Pydantic & dotenv for config

---

## 📁 Project Structure

```
server/
 ├── main.py
 ├── config.py
 ├── services/
 │   ├── llm_service.py
 │   ├── search_service.py
 │   └── sort_source_service.py
 ├── pydantic_models/
 ├── requirements.txt
 ├── .env.example
render.yaml
Procfile (optional)
```

---

## 🗝️ Environment Variables

Create a `.env` file:

```env
GEMINI_API_KEY=your-gemini-api-key
TAVILY_API_KEY=your-tavily-api-key
```

---

## 🧩 Local Development

```bash
# 1. Create a virtual env
python -m venv venv

# 2. Activate it
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run the server
uvicorn main:app --reload
```

Docs: [http://localhost:8000/docs](http://localhost:8000/docs)
WebSocket: ws\://localhost:8000/ws/chat

---

## 🌐 Deploy to Render

1️⃣ Commit your code with `requirements.txt` and `render.yaml`.

Example `render.yaml`:

```yaml
services:
  - type: web
    name: perplexity-backend
    env: python
    plan: free
    buildCommand: ""
    startCommand: uvicorn main:app --host 0.0.0.0 --port $PORT
    envVars:
      - key: GEMINI_API_KEY
        sync: false
      - key: TAVILY_API_KEY
        sync: false
```

2️⃣ Push to GitHub.

3️⃣ Go to [https://dashboard.render.com/](https://dashboard.render.com/), click **New + → Web Service**, connect your repo.

4️⃣ Add your environment variables (`GEMINI_API_KEY` and `TAVILY_API_KEY`).

5️⃣ Deploy! Your backend will be live at:

```
https://your-app-name.onrender.com
```

---

## ✅ Endpoints

### POST `/chat`

Input:

```json
{
  "query": "What is FastAPI?"
}
```

Response: full answer generated by the LLM.

---

### WebSocket `/ws/chat`

1. Connect to `wss://your-app-name.onrender.com/ws/chat`
2. Send `{ "query": "Your question" }`
3. Receive:

   * `search_result`
   * streamed `content` chunks

---

## 📜 License

MIT

---

**FastAPI. Gemini. Search. Sorted. 🚀**
